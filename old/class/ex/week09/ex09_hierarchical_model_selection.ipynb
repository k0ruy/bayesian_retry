{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pymc3 as pm\n",
    "import arviz as az\n",
    "import pandas as pd\n",
    "#import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Factory data\n",
    "\n",
    "The following dataset contains quality control measurements from 6\n",
    "machines in a factory (range: 0-120, units of the measurements are irrelevant here). \n",
    "\n",
    "In the dataset, each column contains the measurements for a single machine. Quality control measurements are expensive and time-consuming, so only 5 measurements were done for each machine. \n",
    "\n",
    "In addition to the existing machines, we are interested in the quality of another machine (the seventh machine) which is not in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_wide = pd.read_csv(\"factory.csv\")\n",
    "df_wide.set_index(\"measurement\", inplace=True)\n",
    "df_wide.columns.name = \"machine\"\n",
    "df_wide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Transform the dataset to the long format: one row per machine per measurement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "A \"long\" format is more convenient for the following analyises. Let us *melt* the dataframe!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.melt(df_wide.reset_index(),\n",
    "             id_vars=[\"measurement\"],\n",
    "             value_vars=['M1', 'M2', 'M3', 'M4', 'M5', 'M6'],\n",
    "             value_name='quality')\n",
    "df[\"machine\"] = df[\"machine\"].astype(\"category\") # useful for group analysis (with pymc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the category column has the useful properies `cat.categories` (all the possible values of the categorical variable) and `cat.codes` (an equivalent integer representation of the variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"machine\"].cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[\"machine\"].cat.codes.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Some traditional data analysis (data-challenge style)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "* Obtain the global mean and standard deviation of the quality measurement (pooled mean/standard deviation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df[\"quality\"].mean(), df[\"quality\"].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "* Plot a histogram and a boxplot of the quality measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sns.histplot(df[\"quality\"]);\n",
    "#px.histogram(df[\"quality\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df[\"quality\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "* Obtain the mean and standard deviation of quality measurement, for the different machines (unpooled mean/standard deviation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.groupby(\"machine\")[[\"quality\"]].agg([\"mean\", \"std\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "* Draw boxplots of quality for the different factories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.boxplot(data=df, x=\"quality\", y=\"machine\");\n",
    "#px.box(df, x=\"quality\", y=\"machine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Even from a classical analysis, there seems to be evidence that different machines have different quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Pooled Bayesian Model\n",
    "\n",
    "Consider the following *pooled* Bayesian model:\n",
    "\\begin{align*}\n",
    "\\mu &\\sim N(90, 10) \\\\\n",
    "\\sigma &\\sim \\text{HalfNormal}(36) \\\\\n",
    "\\vec{y}_{ij} &\\sim N(\\mu, \\sigma) \\\\\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Discuss the pooled model and its underlying hypotheses "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Implement the pooled model in pymc3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Unpooled Bayesian Model\n",
    "\n",
    "Consider the following Bayesian unpooled model\n",
    "\\begin{align*}\n",
    "\\mu_{j} &\\sim {N}(90, 20) \\\\\n",
    "\\sigma_{j} &\\sim \\text{HalfNormal}(23) \\\\\n",
    "\\vec{y}_{ij} &\\sim {N}(\\mu_j, \\sigma_j) \\\\\n",
    "\\end{align*}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Discuss the unpooled model and its underlying hypotheses "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Implement the unpooled model in pymc3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "* Compare the sample unpooled standard deviation with the bayesian estimate. What do you observe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Hierarchical model, common std\n",
    "\n",
    "Consider the following Bayesian hierarchical model:\n",
    "\n",
    "\\begin{align*}\n",
    "\\mu_\\mu & \\sim N(90, 10)\\\\\n",
    "\\sigma_\\mu  & \\sim \\text{HalfNormal}(30) \\\\\n",
    "\\mu_{j} &\\sim {N}(\\mu_\\mu, \\sigma_\\mu) \\\\\n",
    "\\sigma &\\sim \\text{HalfNormal}(23) \\\\\n",
    "\\vec{y}_{ij} &\\sim {N}(\\mu_j, \\sigma) \\\\\n",
    "\\end{align*}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Discuss the hierarchical model and its underlying hypotheses "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Implement the hierarchical model in pymc3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection \n",
    "\n",
    "What is the best model ultimately? In our case: Pooled, Unpooled, or Hierarchical?\n",
    "\n",
    "\n",
    "To answer this question, we need a **model selection** strategy/metric.\n",
    "\n",
    "* You know metrics for point regression models (mse, rmse, mae,...)\n",
    "* You know metrics for point classification models (accuracy, prediciton, recall...)\n",
    "\n",
    "\n",
    "### The WAIC Criterion \n",
    "To score full Bayesian models, we need a metric that evaluates a (sample-based approximation of a) *distribution*. \n",
    "\n",
    "* A popular metric to score a distribution is the log-pointwise-predictive-density ${\\rm lpd}(y, \\Theta)$:\n",
    "$$ {\\rm lpd}(y, \\Theta) = \\sum_i \\log \\frac{1}{S} \\sum_s p(y_i | \\Theta_s),$$\n",
    "where $y$ are the observations and $\\Theta$ is the sample-based approximation of the posterior ($\\Theta_s$ is a single MCMC draw). It is the (approximate) logarithm of the expected likelihood (the higher, the better)!\n",
    "\n",
    "\n",
    "* The ${\\rm lpd}(y, \\Theta)$ generally increases for increasing model complexity and it is thus prone to overfitting when used on the same data used for model building. It should be evaluated with fresh data in (cross)-validation.\n",
    "\n",
    "* The WAIC criterion (the lower, the better) balances high ${\\rm lpd}$ and low model complexity explicitly. It can be applied directly on the training data $y$!\n",
    "\n",
    "\\begin{align}\n",
    "{\\rm WAIC}(y, \\Theta) &= -2(\\rm{lpd} - p_{\\rm waic}).\\\\\n",
    " p_{{\\rm waic}} &= \\sum_i {\\rm var}_{\\theta} \\log p(y_i|\\theta)\n",
    "\\end{align}\n",
    "\n",
    "* The WAIC is equivalent up to a factor to the ${\\rm elpd}$, the *expected* $\\rm{lpd}$ on fresh data (the higher, the better):\n",
    "\n",
    "$${\\rm elpd}(y, \\Theta) = \\rm{lpd} - p_{\\rm waic}.$$\n",
    "\n",
    "Advantages of WAIC/elpd:\n",
    "\n",
    "* Well-defined both for continuous and for categorical observations\n",
    "* Applicable to Bayesian models returning point-wise estimates\n",
    "* Applicable to the training data directly (built-in complexity penalty)\n",
    "* Works well in practice\n",
    "\n",
    "Note: WAIC stands for Widely Applicable Information Criterion!\n",
    "\n",
    "### The WAIC Criterion in arviz\n",
    "\n",
    "Arviz has a built-in function `az.waic` to compute the WAIC (actually, as of v0.12.1, arviz computes the ${\\rm elpd}$, see <a href=\"https://python.arviz.org/en/v0.12.1/api/generated/arviz.waic.html?highlight=waic\">documentation</a>):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.waic(trace_pooled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an even more convenient method to evaluate the criterion on several models and rank them according to the WAIC criterion (from best to worst, ascending WAIC/descending elpd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#with factory_pooled, factory_separate, factory_hierarchical:\n",
    "comp_df = az.compare({\"model_pooled\": trace_pooled,\n",
    "                      \"model_unpooled\": trace_unpooled,\n",
    "                      \"model_hierarchical\": trace_hierarchical},\n",
    "                      ic=\"waic\") # ic stands for \"information criterion\"\n",
    "comp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "az.plot_compare(comp_df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posterior predictions of new measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Given the pooled model, make a prediction for a new measurement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Given the unpooled model, make a prediction for a new measurement of the machine M1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "221c891a34d53b6a976517fba14e87e2d44925797743ab4436332eb8ae3ca627"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
